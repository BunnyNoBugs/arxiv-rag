{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG Evaluation",
   "id": "d2a5296b8e7c331d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:44:31.151278Z",
     "start_time": "2025-01-20T12:44:31.137271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')"
   ],
   "id": "3e52cadf9c06cd2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-20T12:44:32.282200Z",
     "start_time": "2025-01-20T12:44:31.195064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from rag.rag_pipeline import RAGPipeline, GPTunnelLLM\n",
    "from langchain_community.retrievers import ArxivRetriever\n",
    "from langsmith import Client, evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "from langchain import hub\n",
    "from langchain_mistralai import ChatMistralAI"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:45:06.055483Z",
     "start_time": "2025-01-20T12:45:00.629088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = ArxivRetriever(\n",
    "        top_k_results=3,\n",
    "        get_full_documents=False,  # gives errors with MuPDF when True\n",
    "        doc_content_chars_max=10000000000\n",
    "    )\n",
    "\n",
    "gptunell_key = os.environ.get('GPTUNNEL_API_KEY')\n",
    "gptunnel_llm = GPTunnelLLM(api_key=gptunell_key)\n",
    "\n",
    "assistant = RAGPipeline(llm=gptunnel_llm, retriever=retriever)\n",
    "\n",
    "# Example query\n",
    "question = \"How does ImageBind model bind multiple modalities into a single embedding space? Tell me in detail.\"\n",
    "response = assistant.handle_user_input(question)\n",
    "print(response)"
   ],
   "id": "7976c2b4629d0aae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageBind models bind multiple modalities into a single embedding space by leveraging a learnable bind network. This network aligns the embedding space between the language model and the image encoder. During training, the image features transformed by the bind network are added to the word tokens of all layers in the language model. This process progressively injects visual instructions via an attention-free and zero-initialized gating mechanism. The joint embedding from ImageBind enables the model to exhibit superior multi-modality instruction-following capabilities. During inference, the multi-modality inputs are fed into the corresponding ImageBind encoders, and processed by a proposed visual cache model for further cross-modal embedding enhancement. This approach effectively mitigates the training-inference modality discrepancy and allows the model to respond to instructions of diverse modalities with significant language generation quality.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:45:06.135453Z",
     "start_time": "2025-01-20T12:45:06.114463Z"
    }
   },
   "cell_type": "code",
   "source": "langsmith_client = Client()",
   "id": "57fbaa23200e2699",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:45:06.998153Z",
     "start_time": "2025-01-20T12:45:06.967153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_questions_df = pd.read_csv('data/evaluation_questions.csv')\n",
    "dataset_name = \"Arxiv RAG Evaluation Questions\""
   ],
   "id": "93278ff35ef933ae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:45:09.633062Z",
     "start_time": "2025-01-20T12:45:09.627057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def correct_answer(root_run: Run, example: Example) -> dict:\n",
    "    score = root_run.outputs.get(\"output\") == example.outputs.get(\"answer\")\n",
    "    return {\"score\": int(score), \"key\": \"correct_answer\"}"
   ],
   "id": "b4fc8891c79212d3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:45:50.404550Z",
     "start_time": "2025-01-20T12:45:23.434924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = evaluate(\n",
    "    lambda inputs: assistant.handle_user_input(inputs[\"question\"]),\n",
    "    data=dataset_name,\n",
    "    evaluators=[correct_answer],\n",
    "    experiment_prefix=\"Arxiv RAG Queries\",\n",
    "    # description=\"Testing the baseline system.\",  # optional\n",
    ")"
   ],
   "id": "9a4dcfee9c114b66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Arxiv RAG Queries-0830e2e8' at:\n",
      "https://smith.langchain.com/o/76b2dc9d-4b98-4e5e-983b-623eb76c0ac6/datasets/62c45b24-543f-4290-aeb6-cb696dd9cb06/compare?selectedSessions=b86285f6-8d11-45af-ab1c-96477e605178\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26570306399f4f8f85c8d296e452fe3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:49:57.821546Z",
     "start_time": "2025-01-20T12:49:57.805925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"Use this for answer evaluation\"\"\"\n",
    "    response = assistant.handle_user_input(example[\"question\"])\n",
    "    return {\"answer\": response}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
    "    response = assistant.handle_user_input(example[\"question\"], return_retrieved_docs=True)\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"retrieved_docs\"]}"
   ],
   "id": "66a62cff128184d2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Response vs reference answer",
   "id": "23b45e2c370e60ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T18:53:31.277407Z",
     "start_time": "2024-12-23T18:53:30.313772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = prompt = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Get question, ground truth answer, RAG chain answer\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    reference = example.outputs[\"ground_truth\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM grader\n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-large-latest\",\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "        # other params...\n",
    "    )\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "    \n",
    "    time.sleep(3) # isn't clear if this helps\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ],
   "id": "47677cc7484715ea",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T18:42:27.571600Z",
     "start_time": "2024-12-23T18:42:27.546601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatMistralAI(\n",
    "        model=\"mistral-large-latest\",\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "        # other params...\n",
    "    )"
   ],
   "id": "f1d8a2dcce9770ea",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T18:42:49.162436Z",
     "start_time": "2024-12-23T18:42:48.609081Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke('who created you?')",
   "id": "beecbb374ad0d192",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I was created by Mistral AI.', response_metadata={'token_usage': {'prompt_tokens': 7, 'total_tokens': 15, 'completion_tokens': 8}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-5de10ec5-3165-4559-96bc-11b8b4a33a13-0', usage_metadata={'input_tokens': 7, 'output_tokens': 8, 'total_tokens': 15})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T18:54:15.395635Z",
     "start_time": "2024-12-23T18:53:35.055894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_results = evaluate(\n",
    "    predict_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_evaluator],\n",
    "    experiment_prefix=\"rag-answer-v-reference\",\n",
    ")"
   ],
   "id": "91bcd266a9baaaa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-answer-v-reference-3c61724d' at:\n",
      "https://smith.langchain.com/o/76b2dc9d-4b98-4e5e-983b-623eb76c0ac6/datasets/62c45b24-543f-4290-aeb6-cb696dd9cb06/compare?selectedSessions=0cf2c847-7349-4625-b365-08df545700f5\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2388f54513b4cfb825d6c3fb4368bfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 54318d7d-e66f-4e28-adf7-7ef4afbb546b: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 8c701819-99b4-4d45-bef2-81a37a82a089: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 699b87e0-6ab1-4004-96d2-a148fd30928c: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run a91d5d40-fdfc-4a77-8c26-3662b9568176: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 9b8fa4a0-b5e3-490c-991b-b54f9d36ce03: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 393b7e5d-c095-4640-818d-b1a4271a899d: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 58dcf6fa-62b4-4c3b-9129-350ed255de40: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run a4b9ba80-7895-45c9-8573-d541a63e98cf: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 9cca6778-be05-4fa8-bb6f-f1abfa123056: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 60881a05-1a58-4ac8-8e01-ca4bc61cf282: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 3d00d61b-c8ad-48b6-8f39-7ed2ba31bbe9: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-21-830c7579816c>\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Response vs input",
   "id": "e1395f1cd3581cac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T18:54:34.571552Z",
     "start_time": "2024-12-23T18:54:33.562068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grade prompt\n",
    "grade_prompt_answer_helpfulness = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer helpfulness\n",
    "    \"\"\"\n",
    "\n",
    "    # Get question, ground truth answer, RAG chain answer\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM grader\n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-large-latest\",\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "        # other params...\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}"
   ],
   "id": "60ebfc83972ff9f4",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T18:55:15.313148Z",
     "start_time": "2024-12-23T18:54:38.293425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_results = evaluate(\n",
    "    predict_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_helpfulness_evaluator],\n",
    "    experiment_prefix=\"rag-answer-helpfulness\",\n",
    ")"
   ],
   "id": "a7f3b8fcbc68693e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-answer-helpfulness-60953126' at:\n",
      "https://smith.langchain.com/o/76b2dc9d-4b98-4e5e-983b-623eb76c0ac6/datasets/62c45b24-543f-4290-aeb6-cb696dd9cb06/compare?selectedSessions=9eeef7bd-3168-410e-b45d-32ed240c68a7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87d07448cbec4aa1b9fd9670a12df592"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run d3a1cadd-d07a-4168-bea6-dd2e39b71ac8: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 1ffb623b-8796-4657-bbae-e2b887961830: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 7c3e27b9-af08-4a23-9c1d-04db2577d261: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 80992d7c-d255-474e-b1e7-5c349ae4ed12: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 15e11c45-93c4-473f-8146-aa8eacf9f556: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run dcb30ce0-1e61-47ae-8f77-28e9e6bea18b: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run d1b7d736-f10b-40ad-b985-0cf02c2cf7b5: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run c25ae0dc-4774-4c7a-923f-9440230583fe: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run b258bd5a-d092-4890-baec-261a1039cd22: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 83e3ae7a-6106-4850-87f4-c04722ec8633: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-23-f5956559c19e>\", line 27, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Response vs retrieved docs",
   "id": "61271b50cdecf8e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:50:06.782023Z",
     "start_time": "2025-01-20T12:50:05.202991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prompt\n",
    "grade_prompt_hallucinations = hub.pull(\"langchain-ai/rag-answer-hallucination\")\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for generation hallucination\n",
    "    \"\"\"\n",
    "\n",
    "    # RAG inputs\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "\n",
    "    # RAG answer\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM grader\n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-large-latest\",\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "        # other params...\n",
    "    )\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Get score\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}"
   ],
   "id": "5e958202248f1ad6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:51:10.065700Z",
     "start_time": "2025-01-20T12:50:10.457815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_hallucination_evaluator],\n",
    "    experiment_prefix=\"rag-answer-hallucination\",\n",
    ")"
   ],
   "id": "10dd3e4d01a1d069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-answer-hallucination-b9b3b46b' at:\n",
      "https://smith.langchain.com/o/76b2dc9d-4b98-4e5e-983b-623eb76c0ac6/datasets/62c45b24-543f-4290-aeb6-cb696dd9cb06/compare?selectedSessions=1f66ff08-9880-4e3a-a56a-4a56746750ca\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b512ed78d76b4f8b88bfa50a3d75c415"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run ba02342f-b819-4a27-900d-98ab672e24ce: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 4fdeae6e-417d-453a-ac92-b2b73f7dca9f: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 97ed87b7-7a49-4303-b0eb-a3bbd67354fa: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 87430925-7f86-4515-a01a-08dc0adf0a78: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 7938ded7-bdbf-46e8-a1f2-f1c67df95e3e: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 0ecdd562-e4f4-41e8-9661-1574b2b685be: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 29e472a8-580f-495a-b698-3966a3ca2fc7: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 1c18f9f8-7aa9-47f8-9400-1cab468f1a2f: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 84e6b532-6a3d-48ab-9d24-0df7e0a14faf: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run f2c840ab-c3d1-465e-9cc9-23bcb6053732: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 93f83048-b3a7-40a8-a623-8dd25d552137: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-9-bf043159ce4b>\", line 28, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieved docs vs input",
   "id": "6eeeaf4ecc209ed8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:57:06.419517Z",
     "start_time": "2025-01-20T12:57:05.096977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grade prompt\n",
    "grade_prompt_doc_relevance = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "def docs_relevance_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for document relevance\n",
    "    \"\"\"\n",
    "\n",
    "    # RAG inputs\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "\n",
    "    # LLM grader\n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-large-latest\",\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "        # other params...\n",
    "    )\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_doc_relevance | llm\n",
    "\n",
    "    # Get score\n",
    "    score = answer_grader.invoke({\"question\":input_question,\n",
    "                                  \"documents\":contexts})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"document_relevance\", \"score\": score}"
   ],
   "id": "97c4113920f148e9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:57:39.202295Z",
     "start_time": "2025-01-20T12:57:06.438517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context,\n",
    "    data=dataset_name,\n",
    "    evaluators=[docs_relevance_evaluator],\n",
    "    experiment_prefix=\"rag-doc-relevance\",\n",
    ")"
   ],
   "id": "3c481a92817423e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-doc-relevance-c869f91e' at:\n",
      "https://smith.langchain.com/o/76b2dc9d-4b98-4e5e-983b-623eb76c0ac6/datasets/62c45b24-543f-4290-aeb6-cb696dd9cb06/compare?selectedSessions=3c752f7d-e203-4f2c-ac17-6b22c69eb36a\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4ab363b0e5347d4ab5fac19e6ad51aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run 2c86c913-53d4-48c3-bc49-dccebcdd0d97: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run 46ee782c-3ec2-4e6a-9de4-d36ba8c9ef0b: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run daebb43a-f27e-4a2f-a989-fc4185c1eab8: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run 96128041-40e4-47f4-932a-fbf971356faf: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run e06303e9-95f6-4266-8ba2-dbf0f6443df6: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run 5db90654-d8b4-4344-aded-0b702b3cf73a: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run 02c01606-6033-4308-9866-27f447c27e4a: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run edac019b-e120-4cf8-ab11-0aa972b818e5: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
      "Error running evaluator <DynamicRunEvaluator docs_relevance_evaluator> on run 4983a582-47c0-48e0-8217-7b0d4dbb47a7: HTTPStatusError('Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langsmith\\run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"<ipython-input-11-15f1a8fa1611>\", line 25, in docs_relevance_evaluator\n",
      "    score = answer_grader.invoke({\"question\":input_question,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 531, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 453, in completion_with_retry\n",
      "    rtn = _completion_with_retry(**kwargs)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 450, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\langchain_mistralai\\chat_models.py\", line 168, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "108c66e0522b2acd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
